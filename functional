//note: change name for index.ts
import { HfInference } from "@huggingface/inference";
import readlineSync from "readline-sync";
import dotenv from "dotenv";

dotenv.config();

const HF_API_KEY = process.env.HUGGINGFACE_API_KEY as string;
const client = new HfInference(HF_API_KEY);

async function main() {
  console.log("Mini práctica IA con Hugging Face (modo chat)");
  console.log("Escribe 'salir' para terminar.\n");

  // Historial de mensajes para mantener el contexto
  const messages: { role: "system" | "user" | "assistant"; content: string }[] = [
    { role: "system", content: "Eres un asistente útil y respondes en español." },
  ];

  while (true) {
    const userInput = readlineSync.question("Tú: ");

    if (userInput.toLowerCase() === "salir") {
      console.log("¡Hasta luego!");
      break;
    }

    // Agregar input del usuario al historial
    messages.push({ role: "user", content: userInput });

    try {
      const completion = await client.chatCompletion({
        model: "google/gemma-2-2b-it",
        messages,
        max_tokens: 200,
      });

      const respuesta = completion.choices[0].message.content ?? "";

      console.log("IA:", respuesta, "\n");

      // Agregar respuesta de la IA al historial
      messages.push({ role: "assistant", content: respuesta });
    } catch (err: any) {
      console.error("Error:", err.message || err);
    }
  }
}

main();
